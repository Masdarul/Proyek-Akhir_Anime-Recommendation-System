# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o2BgQkchdSrAeP_nIB4VZamK7RJn397_

## **Proyek Akhir Machine Learning Terapan : Rekomendasi Sistem (Anime)**
**Nama: Masdarul Rizqi** <br>
**Email: m.rizqi1221@gmail.com** <br>
**ID Dicoding: masdarulrizqi**
### **Memanggil Libray atau Modul**
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import os, zipfile

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, Model, regularizers
from sklearn.metrics.pairwise import linear_kernel

local_zip = './zip/Anime Recommendations Database.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('./Data')
zip_ref.close()

"""## **Data Understanding**"""

directory = "./data"

data = {}

for file in os.listdir(directory):
    dataframe = os.path.splitext(file)[0]
    data[dataframe] = pd.read_csv(os.path.join(directory, file), delimiter=",")

df_anime = data['anime']
df_anime.head()

df_rating = data['rating']
df_rating.head()

print(f"Mengecek dimension pada dataset anime : {df_anime.shape}")
print(f"Mengecek dimension pada dataset Rating : {df_rating.shape}")

"""## **Univariate Exploratory Data Analysis**

#### Anime Dataset
Attribute  | Keterangan
------------- | -------------
Anime_id | merepresentasikan Id unik untuk setiap anime
Name | merepresentasikan judul untuk setiap Anime
genre | merepresentasikan genre untuk setiap Anime
Type | merepresentasikan tipe untuk setiap Anime
Episodes | merepresentasikan jumlah episode untuk setiap Anime

#### Ratings Dataset

Attribute  | Keterangan
------------- | -------------
user_id | merepresentasikan Id unik untuk setiap penonton
anime_id | merepresentasikan Id unik untuk setiap anime    
rating | merepresentasikan penilaian yang diberikan oleh penonton

#### **Mengecek Tipe data**
"""

df_anime.info()

df_rating.info()

"""### **Mengecek deskripsi**"""

df_anime.describe()

df_rating.describe()

"""### **Mengecek jumlah baris data dari setiap nilai unik**"""

print(f'Jumlah Anime : {len(df_anime.anime_id.value_counts())}')
print(f'Jumlah Penonton : {len(df_rating.user_id.value_counts())}')

df_anime['genre'].value_counts()

df_rating['rating'].value_counts().sort_index(ascending=False)

anime_stat = df_rating.groupby('anime_id').agg({'rating': 'sum', 'user_id': 'count'}).reset_index()
anime_stat.columns = ['anime_id', 'rating', 'num_users']
result_df = pd.merge(df_anime, anime_stat, on='anime_id')
result_df = result_df.sort_values(by='rating_y', ascending=False)
top_rated_anime = result_df.head(10)
print(top_rated_anime[['name', 'rating_y', 'num_users']])

anime_stat = df_rating.groupby('anime_id').agg({'rating': 'sum', 'user_id': 'count'}).reset_index()
anime_stat.columns = ['anime_id', 'rating', 'num_users']
result_df = pd.merge(df_anime, anime_stat, on='anime_id')
result_df = result_df.sort_values(by='rating_x', ascending=False)
top_rated_anime = result_df.head(10)
print(top_rated_anime[['name', 'rating_x', 'num_users']])

genre_stats = pd.merge(df_anime, anime_stat, on='anime_id')
genre_stats = genre_stats.assign(genre=result_df['genre'].str.split('|')).explode('genre')

genre_stats = genre_stats.groupby('genre').agg({'rating_y': 'mean', 'num_users': 'sum'}).reset_index()
top_genre_ratings = genre_stats.sort_values(by='rating_y', ascending=False)
top_genre_ratings[['genre', 'rating_y', 'num_users']]

genre_stats = pd.merge(df_anime, anime_stat, on='anime_id')
genre_stats = genre_stats.assign(genre=result_df['genre'].str.split('|')).explode('genre')

genre_stats = genre_stats.groupby('genre').agg({'rating_x': 'mean', 'num_users': 'sum'}).reset_index()
top_genre_ratings = genre_stats.sort_values(by='rating_x', ascending=False)
top_genre_ratings[['genre', 'rating_x', 'num_users']]

"""## **Visualisasi Data**"""

plt.figure(figsize=(14, 14))

value_counts = df_anime['genre'].value_counts().head(10)
value_counts.plot(kind='pie', autopct='%1.1f%%', startangle=90)

plt.title('Distribusi Genre Anime Teratas (Top 10)')
plt.ylabel('')

plt.show()

top_genre_ratings_sorted = top_genre_ratings.sort_values(by='num_users', ascending=False)
top_15_genres = top_genre_ratings_sorted.head(15)
fig, ax1 = plt.subplots(figsize=(24, 12))

ax1.set_xlabel('Tata-rata Rating')
ax1.set_ylabel('Genre')
sns.barplot(x='rating_x', y='genre', data=top_15_genres, color='skyblue', ax=ax1, edgecolor='black')
ax1.tick_params(axis='x')

ax2 = ax1.twiny()
color = 'salmon'
ax2.set_xlabel('Jumlah Penonton', color='black')
ax2.plot(top_15_genres['num_users'], top_15_genres['genre'], color=color, marker='o')
ax2.tick_params(axis='x', labelcolor='black')

plt.yticks(fontsize=12)

ax1.grid(axis='x', linestyle='--', alpha=0.7)

fig.tight_layout()
plt.title('Distribusi Rata-rata Rating Penonton Terhadap Genre Anime (Top 15)', fontsize=16)
plt.show()

plt.figure(figsize=(16, 4))
rating = df_rating['rating'].value_counts().sort_index().index
df_rating['rating'].value_counts().sort_index().plot(kind='bar', color='skyblue', edgecolor='black')
plt.title('Distribusi rating')
plt.xlabel('Rating')
plt.ylabel('Jumlah rating')
plt.xticks(rotation=0)
plt.show()

plt.figure(figsize=(10, 6))
plt.barh(top_rated_anime['name'], top_rated_anime['rating_x'], color='skyblue', edgecolor='black')
plt.xlabel('Jumlah Rating')
plt.title('Distribusi 10 Anime Terbaik berdasarkan akumulasi Rating')
plt.gca().invert_yaxis()
plt.show()

fig, ax1 = plt.subplots(figsize=(16, 8))

color = 'skyblue'
ax1.set_xlabel('Rata-rata Rating')
ax1.set_ylabel('Anime')
ax1.barh(top_rated_anime['name'], top_rated_anime['rating_x'], color=color, edgecolor='black')
ax1.tick_params(axis='x')

ax2 = ax1.twiny()
color = 'salmon'
ax2.set_xlabel('Jumlah Penonton', color='black')
ax2.plot(top_rated_anime['num_users'], top_rated_anime['name'], color=color, marker='o')
ax2.tick_params(axis='x', labelcolor='black')

plt.yticks(fontsize=12)

ax1.grid(axis='x', linestyle='--', alpha=0.7)

fig.tight_layout()
plt.title('Distribusi Anime terpopuler berdasarkan rata-rata rating dan jumlah penonton (Top 10)', fontsize=16)
plt.show()

"""## **Data Preprocessing**
#### **Anime Dataset**
"""

df_anime[df_anime['name'].duplicated()]

df_anime[df_anime['name'] == "Shi Wan Ge Leng Xiaohuan"]

df_anime[df_anime['name'] == "Saru Kani Gassen"]

df_anime['name'].isnull().sum()

"""#### Rating dataset"""

df_rating.isnull().sum()

"""## **Model Development dengan Content Based Filtering**"""

anime_data = df_anime
anime_data.sample(5)

anime_data = anime_data.dropna(subset=['genre'])
tfidf_vectorizer = TfidfVectorizer()
tfidf_matrix = tfidf_vectorizer.fit_transform(anime_data['genre'])
feature_names = pd.DataFrame(tfidf_vectorizer.get_feature_names_out(), columns=['genre'])

anime_data['genre'].fillna('Unknown', inplace=True)
tfidf_vectorizer = TfidfVectorizer()
tfidf_matrix = tfidf_vectorizer.fit_transform(anime_data['genre'])
feature_names = pd.DataFrame(tfidf_vectorizer.get_feature_names_out(), columns=['genre'])
feature_names

tfidf_matrix.shape

"""#### **Mengubah matrix menjadi dense**"""

tfidf_matrix.todense()

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tfidf_vectorizer.get_feature_names_out(),
    index=anime_data.name
).sample(24, axis=1).sample(5, axis=0)

"""#### **Menghitung Derajat Kesamaan (Cosine Similarity)**"""

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

cosine_sim_df = pd.DataFrame(cosine_sim, index=anime_data['name'], columns=anime_data['name'])
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

cosine_sim_df.shape

"""## **Hasil Rekomendasi film berdasarkan genre**"""

def anime_recommendations(name, similarity_data=cosine_sim_df, items=anime_data[['name', 'genre']], k=5):

    index = similarity_data.loc[:, name].to_numpy().argpartition(range(-1, -k, -1))
    closest = similarity_data.columns[index[-1:-(k+2):-1]].drop(name, errors='ignore')
    recommendations = pd.DataFrame(closest).merge(items).head(k)

    return recommendations

anime_data[anime_data.name.eq('One Piece')]

anime_recommendations('One Piece')

"""## **Model Development dengan Collaborative Filtering**"""

rating_data = df_rating
user_to_user_encoded = {user_id: i for i, user_id in enumerate(rating_data['user_id'].unique())}
user_encoded_to_user = {i: user_id for i, user_id in enumerate(rating_data['user_id'].unique())}

anime_to_anime_encoded = {anime_id: i for i, anime_id in enumerate(rating_data['anime_id'].unique())}
anime_encoded_to_anime = {i: anime_id for i, anime_id in enumerate(rating_data['anime_id'].unique())}

rating_data['User'] = rating_data['user_id'].map(user_to_user_encoded)
rating_data['Anime'] = rating_data['anime_id'].map(anime_to_anime_encoded)

num_users = len(user_to_user_encoded)
num_movies = len(anime_encoded_to_anime)
min_rating = rating_data['rating'].min()
max_rating = rating_data['rating'].max()

value = pd.DataFrame({'Value Count': [num_users, num_movies, min_rating, max_rating]},
                     index=['Number of User', 'Number of Movie', 'Min Rating', 'Max Rating'])

value

"""#### **Membagi Data untuk Training dan Validasi**"""

rating_data = rating_data.sample(frac=1, random_state=42)
rating_data.sample(5)

x = rating_data[['User', 'Anime']].values
y = (rating_data['rating'] - min_rating) / (max_rating - min_rating)

x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)

print(x, y)

"""#### **Proses Training**"""

class RecommenderNet(tf.keras.Model):
    def __init__(self, num_users, num_anime, embedding_size, dropout_rate=0.2, **kwargs):
        super(RecommenderNet, self).__init__(**kwargs)
        self.num_users = num_users
        self.num_anime = num_anime
        self.embedding_size = embedding_size

        self.user_embedding = layers.Embedding(
            num_users,
            embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=regularizers.l2(1e-6)
        )
        self.user_embedding_dropout = layers.Dropout(dropout_rate)
        self.user_bias = layers.Embedding(num_users, 1)

        self.anime_embedding = layers.Embedding(
            num_anime,
            embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=regularizers.l2(1e-6)
        )
        self.anime_embedding_dropout = layers.Dropout(dropout_rate)
        self.anime_bias = layers.Embedding(num_anime, 1)

    def call(self, inputs):
        user_vector = self.user_embedding(inputs[:, 0])
        user_vector = self.user_embedding_dropout(user_vector)
        user_bias = self.user_bias(inputs[:, 0])
        anime_vector = self.anime_embedding(inputs[:, 1])
        anime_vector = self.anime_embedding_dropout(anime_vector)
        anime_bias = self.anime_bias(inputs[:, 1])

        dot_user_anime = tf.tensordot(user_vector, anime_vector, 2)
        x = dot_user_anime + user_bias + anime_bias

        return tf.nn.sigmoid(x)

model = RecommenderNet(num_users, num_movies, 50)

model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(),
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

initial_learning_rate = 0.001
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate, decay_steps=10000, decay_rate=0.9, staircase=True
)
optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)

model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(),
    optimizer=optimizer,
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

history = model.fit(
    x=x_train,
    y=y_train,
    batch_size=256,
    epochs=3,
    validation_data=(x_val, y_val)
)

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('Model Metrics')
plt.ylabel('Root Mean Squared Error')
plt.xlabel('Epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""#### **Mendapatkan Rekomendasi Anime**"""

anime = anime_data

# Mengambil sample user
user_id = rating_data.user_id.sample(1).iloc[0]
anime_watched_by_user = rating_data[rating_data.user_id == user_id]

anime_not_watched = anime[~anime['anime_id'].isin(anime_watched_by_user.anime_id.values)]['anime_id']
anime_not_watched = list(
    set(anime_not_watched)
    .intersection(set(anime_to_anime_encoded.keys()))
)

anime_not_watched = [[anime_to_anime_encoded.get(x)] for x in anime_not_watched]
user_encoder = user_to_user_encoded.get(user_id)
user_anime_array = np.hstack(
    ([[user_encoder]] * len(anime_not_watched), anime_not_watched)
)

rating = model.predict(user_anime_array).flatten()

top_rating_indices = rating.argsort()[-10:][::-1]
recommended_anime_ids = [
    anime_encoded_to_anime.get(anime_not_watched[x][0]) for x in top_rating_indices
]
# Showing Recommendations for Users
print('Showing Recommendations for User: {}'.format(user_id))
print('===' * 9)

# anime with High Rating from User
print('anime with High Rating from User')
print('----' * 8)

top_anime_user = (
    anime_watched_by_user.sort_values(
        by='rating',
        ascending=False
    )
    .head(5)
    .anime_id.values
)

anime_df_rows_user = anime[anime['anime_id'].isin(top_anime_user)]
for row in anime_df_rows_user.itertuples():
    print(row.name, ':', row.genre)

print('----' * 8)

# Top 10 anime Recommendation
print('Top 10 anime Recommendations')
print('----' * 8)

recommended_anime = anime[anime['anime_id'].isin(recommended_anime_ids)]
for row in recommended_anime.itertuples():
    print(row.name, ':', row.genre)